{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>TimbreAvg1</th>\n",
       "      <th>TimbreAvg2</th>\n",
       "      <th>TimbreAvg3</th>\n",
       "      <th>TimbreAvg4</th>\n",
       "      <th>TimbreAvg5</th>\n",
       "      <th>TimbreAvg6</th>\n",
       "      <th>TimbreAvg7</th>\n",
       "      <th>TimbreAvg8</th>\n",
       "      <th>TimbreAvg9</th>\n",
       "      <th>...</th>\n",
       "      <th>TimbreCovariance69</th>\n",
       "      <th>TimbreCovariance70</th>\n",
       "      <th>TimbreCovariance71</th>\n",
       "      <th>TimbreCovariance72</th>\n",
       "      <th>TimbreCovariance73</th>\n",
       "      <th>TimbreCovariance74</th>\n",
       "      <th>TimbreCovariance75</th>\n",
       "      <th>TimbreCovariance76</th>\n",
       "      <th>TimbreCovariance77</th>\n",
       "      <th>TimbreCovariance78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  TimbreAvg1  TimbreAvg2  TimbreAvg3  TimbreAvg4  TimbreAvg5  \\\n",
       "0   2001    49.94357    21.47114    73.07750     8.74861   -17.40628   \n",
       "1   2001    48.73215    18.42930    70.32679    12.94636   -10.32437   \n",
       "2   2001    50.95714    31.85602    55.81851    13.41693    -6.57898   \n",
       "3   2001    48.24750    -1.89837    36.29772     2.58776     0.97170   \n",
       "4   2001    50.97020    42.20998    67.09964     8.46791   -15.85279   \n",
       "\n",
       "   TimbreAvg6  TimbreAvg7  TimbreAvg8  TimbreAvg9  ...  TimbreCovariance69  \\\n",
       "0   -13.09905   -25.01202   -12.23257     7.83089  ...            13.01620   \n",
       "1   -24.83777     8.76630    -0.92019    18.76548  ...             5.66812   \n",
       "2   -18.54940    -3.27872    -2.35035    16.07017  ...             3.03800   \n",
       "3   -26.21683     5.05097   -10.34124     3.55005  ...            34.57337   \n",
       "4   -16.81409   -12.48207    -9.37636    12.63699  ...             9.92661   \n",
       "\n",
       "   TimbreCovariance70  TimbreCovariance71  TimbreCovariance72  \\\n",
       "0           -54.40548            58.99367            15.37344   \n",
       "1           -19.68073            33.04964            42.87836   \n",
       "2            26.05866           -50.92779            10.93792   \n",
       "3          -171.70734           -16.96705           -46.67617   \n",
       "4           -55.95724            64.92712           -17.72522   \n",
       "\n",
       "   TimbreCovariance73  TimbreCovariance74  TimbreCovariance75  \\\n",
       "0             1.11144           -23.08793            68.40795   \n",
       "1            -9.90378           -32.22788            70.49388   \n",
       "2            -0.07568            43.20130          -115.00698   \n",
       "3           -12.51516            82.58061           -72.08993   \n",
       "4            -1.49237            -7.50035            51.76631   \n",
       "\n",
       "   TimbreCovariance76  TimbreCovariance77  TimbreCovariance78  \n",
       "0            -1.82223           -27.46348             2.26327  \n",
       "1            12.04941            58.43453            26.92061  \n",
       "2            -0.05859            39.67068            -0.66345  \n",
       "3             9.90558           199.62971            18.85382  \n",
       "4             7.88713            55.66926            28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"data/year_prediction.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                   int64\n",
       "TimbreAvg1            float64\n",
       "TimbreAvg2            float64\n",
       "TimbreAvg3            float64\n",
       "TimbreAvg4            float64\n",
       "                       ...   \n",
       "TimbreCovariance74    float64\n",
       "TimbreCovariance75    float64\n",
       "TimbreCovariance76    float64\n",
       "TimbreCovariance77    float64\n",
       "TimbreCovariance78    float64\n",
       "Length: 91, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As recommended by the owners of the dataset\n",
    "train_df=df.iloc[:463715]\n",
    "test_df=df.iloc[463715:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YearNetwork(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size,128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class YearDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.features=data.drop(['label'],axis=1)\n",
    "        self.labels=data[['label']]\n",
    "        #print(f\"features: {self.features.shape}\\nlabels: {self.labels.shape}\\n\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        feature_items=self.features.iloc[[idx]].to_numpy()\n",
    "        label_items=self.labels.iloc[[idx]].to_numpy()\n",
    "\n",
    "        x=torch.tensor(feature_items,dtype=torch.float32)\n",
    "        y=torch.tensor(label_items,dtype=torch.float32)       \n",
    "\n",
    "        return x,y\n",
    "\n",
    "def train_loop(model,dataloader,optimizer,epoch):\n",
    "    model.train()\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch}: \"):\n",
    "        inputs, labels = batch\n",
    "        labels=torch.flatten(labels)\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        loss=F.mse_loss(torch.ravel(pred), labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test_loop(model,dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in tqdm(dataloader, desc=\"Testing: \"):\n",
    "            pred=model(inputs)\n",
    "\n",
    "            loss_item=F.mse_loss(torch.ravel(pred),torch.ravel(labels)).item()\n",
    "            test_loss+=loss_item\n",
    "            \n",
    "            \n",
    "    test_loss=test_loss / size\n",
    "    print(f'Test loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "lr=.005\n",
    "batch_size=32\n",
    "epochs=10\n",
    "\n",
    "model=YearNetwork(df.shape[1]-1)\n",
    "train_dataset,test_dataset=YearDataset(train_df),YearDataset(test_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "optimizer=optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 90])\n",
      "Labels batch shape: torch.Size([32, 1, 1])\n",
      "tensor([0.1151, 0.2845], grad_fn=<ViewBackward0>)\n",
      "tensor([2006., 2010.])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "features,labels=batch\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "feat = features[:2]\n",
    "label = labels[:2]\n",
    "pred=model(feat)\n",
    "print(torch.ravel(pred))\n",
    "print(torch.flatten(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model,train_dataloader,test_dataloader,optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"==========================================\")\n",
    "        train_loop(model=model,dataloader=train_dataloader,optimizer=optimizer,epoch=epoch+1)\n",
    "        test_loop(model=model,dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 14491/14491 [03:16<00:00, 73.72it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:15<00:00, 101.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 81.63167117828918, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 14491/14491 [03:16<00:00, 73.89it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:15<00:00, 104.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 80.01809287736376, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 14491/14491 [03:16<00:00, 73.87it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:15<00:00, 101.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 80.33218011897466, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14491/14491 [03:14<00:00, 74.62it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 100.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 79.31125541185638, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 14491/14491 [03:21<00:00, 72.01it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 97.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 79.7959945428024, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 14491/14491 [03:21<00:00, 71.97it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 100.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 79.26725671724436, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 14491/14491 [03:15<00:00, 73.95it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 100.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 83.34137634069226, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 14491/14491 [03:21<00:00, 71.79it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 97.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 78.42303012840806, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 14491/14491 [03:24<00:00, 70.93it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 99.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 83.35907750091269, size: 1613\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 14491/14491 [03:17<00:00, 73.47it/s]\n",
      "Testing: 100%|██████████| 1613/1613 [00:16<00:00, 98.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 78.60077188684566, size: 1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_network(model=model,train_dataloader=train_dataloader,test_dataloader=test_dataloader,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs=5\n",
    "torch.manual_seed(42)\n",
    "model256=YearNetwork(df.shape[1]-1)\n",
    "train_dataloader256 = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_dataloader256 = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "optimizer=optim.Adam(model256.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1811/1811 [02:19<00:00, 13.00it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 43349.65782416045, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1811/1811 [02:22<00:00, 12.74it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.61157816796754, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1811/1811 [02:24<00:00, 12.53it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:15<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.30072729385907, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1811/1811 [3:26:30<00:00,  6.84s/it]      \n",
      "Testing: 100%|██████████| 201/201 [00:13<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.58990698667309, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1811/1811 [02:14<00:00, 13.45it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.74773851081507, size: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#larger batch size\n",
    "train_network(model=model256,train_dataloader=train_dataloader256,test_dataloader=test_dataloader256,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "lr=.002\n",
    "epochs=15\n",
    "model512=YearNetwork(df.shape[1]-1)\n",
    "train_dataloader512 = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_dataloader512 = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "optimizer=optim.Adam(model512.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 905/905 [02:08<00:00,  7.05it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3481823.7825, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 905/905 [02:12<00:00,  6.83it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2353284.2125, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 905/905 [02:15<00:00,  6.69it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1204800.85125, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 905/905 [02:13<00:00,  6.78it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 414527.7215625, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 905/905 [02:17<00:00,  6.57it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 72790.94453125, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 905/905 [02:13<00:00,  6.77it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3953.1326708984375, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 905/905 [02:13<00:00,  6.78it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 108.04751083374023, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 905/905 [02:15<00:00,  6.68it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.79556705474853, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 905/905 [02:12<00:00,  6.82it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.93293361663818, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 905/905 [02:12<00:00,  6.86it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.66033203125, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 905/905 [02:12<00:00,  6.84it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:14<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.29646137237549, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 905/905 [12:05<00:00,  1.25it/s]   \n",
      "Testing: 100%|██████████| 100/100 [00:12<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.43339630126952, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 905/905 [02:04<00:00,  7.26it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.54559627532959, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 905/905 [02:09<00:00,  7.01it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 78.5699792098999, size: 100\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 905/905 [02:08<00:00,  7.02it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:13<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 78.08197334289551, size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Even larger batch size\n",
    "train_network(model=model512,train_dataloader=train_dataloader512,test_dataloader=test_dataloader512,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made larger network\n",
    "class LargerYearNetwork(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size,256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16,1),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "modelLarge=LargerYearNetwork(df.shape[1]-1)\n",
    "train_dataloaderLarge = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "test_dataloaderLarge = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "optimizer=optim.Adam(modelLarge.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1811/1811 [02:22<00:00, 12.72it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2351738.7537313434, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1811/1811 [02:21<00:00, 12.78it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:13<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 413524.0729166667, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1811/1811 [02:24<00:00, 12.55it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3873.8972070798354, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1811/1811 [02:25<00:00, 12.42it/s]\n",
      "Testing: 100%|██████████| 201/201 [27:59<00:00,  8.36s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.28531851697323, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1811/1811 [29:46<00:00,  1.01it/s]   \n",
      "Testing: 100%|██████████| 201/201 [00:13<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.6275488820242, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1811/1811 [02:22<00:00, 12.67it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.48366882551962, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1811/1811 [02:26<00:00, 12.40it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.22810895170146, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1811/1811 [02:27<00:00, 12.26it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:35<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.7742239349517, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1811/1811 [02:28<00:00, 12.20it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.26871615737232, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1811/1811 [02:28<00:00, 12.17it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.72728399020522, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1811/1811 [02:28<00:00, 12.22it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.74743403724177, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1811/1811 [1:09:59<00:00,  2.32s/it]   \n",
      "Testing: 100%|██████████| 201/201 [00:16<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.27089793646513, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1811/1811 [02:14<00:00, 13.49it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 77.73921499679338, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1811/1811 [02:21<00:00, 12.83it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 78.04404198945458, size: 201\n",
      "==========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1811/1811 [02:23<00:00, 12.59it/s]\n",
      "Testing: 100%|██████████| 201/201 [00:14<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 79.08563042635942, size: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#larger Network with 256 batch size\n",
    "train_network(model=modelLarge,train_dataloader=train_dataloaderLarge,test_dataloader=test_dataloaderLarge,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_test_loop(model,dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for inputs,labels in tqdm(dataloader, desc=\"Testing: \"):\n",
    "            pred=model(inputs)\n",
    "\n",
    "            loss_item=F.l1_loss(torch.ravel(pred),torch.ravel(labels)).item()\n",
    "            test_loss+=loss_item\n",
    "            \n",
    "            \n",
    "    test_loss=test_loss / size\n",
    "    print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 201/201 [00:13<00:00, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.052619865284631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#How many years is the 256 batch size model off by on average\n",
    "l1_test_loop(model=model256,dataloader=test_dataloader256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:13<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decades Accuracy: 58.343986054619414% (30123/51630)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#How often does the model get the decade of the song correct\n",
    "def correct_decades(prediction,actual):\n",
    "        #we know the songs range from 1922 to 2011\n",
    "        prediction=[2011 if x > 2011 else 1922 if x < 1922 else x for x in prediction]\n",
    "        prediction=[x%100//10 for x in prediction]\n",
    "        actual=[x%100//10 for x in actual]\n",
    "\n",
    "        return sum(a==b for a,b in zip(prediction,actual))\n",
    "        \n",
    "decade_dataloader = DataLoader(test_dataset, batch_size=256,drop_last=True)\n",
    "# x,y=next(iter(decade_dataloader))\n",
    "# y_hat=model256(x)\n",
    "# print(y_hat.flatten().tolist())\n",
    "# print(y.flatten())\n",
    "\n",
    "\n",
    "h=[1969.7,85,2099.7,2000.4,1989]\n",
    "i=[1965,1924.1,2011.2,2003.6,1999]\n",
    "print(correct_decades(h,i))\n",
    "\n",
    "model256.eval()\n",
    "total=len(decade_dataloader.dataset)\n",
    "correct=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in tqdm(decade_dataloader):\n",
    "        pred_years=model256(inputs).flatten().tolist()\n",
    "\n",
    "        actual_years=labels.flatten().tolist()\n",
    "        correct += correct_decades(pred_years,actual_years)\n",
    "\n",
    "print(f\"Decades Accuracy: {correct/total*100}% ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great!\n",
    "The model gets within about 6 years of when the song was released on average, and as a bonus can correctly guess which decade the song is from more than half the time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse217a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
